{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPe814W9OYftFyG/b0BipSR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NAMHUBB/Nam/blob/main/251202.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow tensorflow-hub opencv-python numpy"
      ],
      "metadata": {
        "id": "_lVfK7XqbVnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 로봇의 눈: 객체 인식 (Object Detection)\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# 1. 사전 학습된 모델 로드 (MobileNet V2 - 빠르고 가벼워 로봇에 적합)\n",
        "# ImageNet 데이터셋으로 학습된 모델입니다.\n",
        "model_url = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\"\n",
        "model = hub.KerasLayer(model_url)\n",
        "\n",
        "# 2. 이미지 전처리 함수 (모델이 요구하는 224x224 크기 및 정규화)\n",
        "def preprocess_image(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    img = img / 255.0  # 0~1 사이로 정규화\n",
        "    img = np.expand_dims(img, axis=0)  # 배치 차원 추가 (1, 224, 224, 3)\n",
        "    return img\n",
        "\n",
        "# 3. 추론 실행\n",
        "try:\n",
        "    image_path = \"robot_view.jpg\"  # 분석할 이미지 경로\n",
        "    input_data = preprocess_image(image_path)\n",
        "\n",
        "    logits = model(input_data)\n",
        "    predicted_class = tf.argmax(logits, axis=-1)\n",
        "\n",
        "    print(f\"예측된 클래스 ID: {predicted_class.numpy()[0]}\")\n",
        "    # 실제 사용 시에는 ImageNet 라벨 맵(Labels map)을 통해 ID를 'Apple', 'Cup' 등의 텍스트로 변환합니다.\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"이미지 로드 실패 또는 오류 발생: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L32shdqFbVln",
        "outputId": "e68cce45-e75a-4010-b2da-f1ad894309c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "예측된 클래스 ID: 783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "\n",
        "# 1. 가상의 센서 데이터 생성 (정상 데이터: 노이즈가 적은 사인파)\n",
        "# 실제로는 로봇의 모터 진동, 전류, 온도 데이터가 들어갑니다.\n",
        "data_size = 1000\n",
        "time_steps = 30\n",
        "x_train = np.sin(np.linspace(0, 50, data_size * time_steps)).reshape(data_size, time_steps)\n",
        "\n",
        "# 2. Autoencoder 모델 정의\n",
        "# 입력 -> 압축(Encoder) -> 복원(Decoder) -> 출력\n",
        "model = models.Sequential([\n",
        "    # Encoder\n",
        "    layers.Dense(16, activation='relu', input_shape=(time_steps,)),\n",
        "    layers.Dense(8, activation='relu'),\n",
        "    # Decoder\n",
        "    layers.Dense(16, activation='relu'),\n",
        "    layers.Dense(time_steps, activation='linear') # 입력과 동일한 크기로 복원\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# 3. 정상 데이터로 학습\n",
        "print(\"모델 학습 시작...\")\n",
        "model.fit(x_train, x_train, epochs=10, batch_size=32, verbose=0)\n",
        "\n",
        "# 4. 이상 탐지 테스트\n",
        "# 고장 난 모터 데이터 (노이즈가 심함)\n",
        "anomaly_data = x_train[0] + np.random.normal(0, 0.5, time_steps)\n",
        "anomaly_data = anomaly_data.reshape(1, time_steps)\n",
        "\n",
        "# 복원 오차 계산\n",
        "reconstruction = model.predict(anomaly_data)\n",
        "loss = tf.keras.losses.mse(reconstruction, anomaly_data)\n",
        "threshold = 0.1 # 임계값 설정\n",
        "\n",
        "if loss.numpy()[0] > threshold:\n",
        "    print(f\"⚠️ 경고: 이상 징후 감지됨! (Loss: {loss.numpy()[0]:.4f})\")\n",
        "else:\n",
        "    print(\"상태 정상.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_W3wT8vbVrA",
        "outputId": "4c19de30-216d-4f32-8fd3-aa747e5c7118"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모델 학습 시작...\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 276ms/step\n",
            "⚠️ 경고: 이상 징후 감지됨! (Loss: 0.3185)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OGCnhx8ibVs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EbUrQDHLbVuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91a34ef0"
      },
      "source": [
        "# Task\n",
        "Ensure that the image file \"robot_view.jpg\" exists in the current working directory, then successfully execute the object recognition model defined in cell `L32shdqFbVln`. If the file does not exist, generate a dummy image named \"robot_view.jpg\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d23c6bc0"
      },
      "source": [
        "## 이미지 파일 존재 여부 확인\n",
        "\n",
        "### Subtask:\n",
        "먼저 `robot_view.jpg` 파일이 현재 작업 디렉토리에 존재하는지 확인합니다. 존재하지 않는다면, 오류가 발생하는 것은 당연합니다. `os.listdir()`을 사용하여 파일 목록을 확인할 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0a70cab"
      },
      "source": [
        "**Reasoning**:\n",
        "To verify the existence of 'robot_view.jpg', I will import the 'os' module and use `os.path.exists()` to check if the file is present in the current working directory, then print the result.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e096877f",
        "outputId": "09d4a91d-dda3-4d88-d8bb-05ddb561294a"
      },
      "source": [
        "import os\n",
        "\n",
        "image_file_name = 'robot_view.jpg'\n",
        "file_exists = os.path.exists(image_file_name)\n",
        "print(f\"'{image_file_name}' 파일 존재 여부: {file_exists}\")\n",
        "\n",
        "# 현재 디렉토리 파일 목록 확인 (디버깅 목적)\n",
        "# print(\"현재 디렉토리 파일 목록:\")\n",
        "# for f in os.listdir('.'):\n",
        "#     print(f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'robot_view.jpg' 파일 존재 여부: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4a55dc77"
      },
      "source": [
        "**Reasoning**:\n",
        "Since 'robot_view.jpg' does not exist, as confirmed by the previous step, I will create a dummy image with this filename using `numpy` and `cv2` to allow the object recognition model to proceed without a file not found error.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b25d33e",
        "outputId": "1ddb2087-5a52-4ed5-96ea-e30c119700f3"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "image_file_name = 'robot_view.jpg'\n",
        "\n",
        "if not os.path.exists(image_file_name):\n",
        "    # Create a dummy image (e.g., a black image or a simple colored square)\n",
        "    dummy_image = np.zeros((224, 224, 3), dtype=np.uint8) # 224x224 black image\n",
        "    # Optionally, draw something on it\n",
        "    cv2.rectangle(dummy_image, (50, 50), (174, 174), (0, 255, 0), -1) # Green square\n",
        "    cv2.imwrite(image_file_name, dummy_image)\n",
        "    print(f\"Dummy image '{image_file_name}' created.\")\n",
        "else:\n",
        "    print(f\"'{image_file_name}' already exists. No new image created.\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dummy image 'robot_view.jpg' created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93eb1277"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the `robot_view.jpg` file has been created, I will re-execute the original object recognition model in cell `L32shdqFbVln` to ensure it runs successfully without the file not found error.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "764b4726",
        "outputId": "bdb6eea4-8ce7-4069-907e-ab86e8c89efd"
      },
      "source": [
        "## 로봇의 눈: 객체 인식 (Object Detection)\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# 1. 사전 학습된 모델 로드 (MobileNet V2 - 빠르고 가벼워 로봇에 적합)\n",
        "# ImageNet 데이터셋으로 학습된 모델입니다.\n",
        "model_url = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\"\n",
        "model = hub.KerasLayer(model_url)\n",
        "\n",
        "# 2. 이미지 전처리 함수 (모델이 요구하는 224x224 크기 및 정규화)\n",
        "def preprocess_image(image_path):\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    img = img / 255.0  # 0~1 사이로 정규화\n",
        "    img = np.expand_dims(img, axis=0)  # 배치 차원 추가 (1, 224, 224, 3)\n",
        "    return img\n",
        "\n",
        "# 3. 추론 실행\n",
        "try:\n",
        "    image_path = \"robot_view.jpg\"  # 분석할 이미지 경로\n",
        "    input_data = preprocess_image(image_path)\n",
        "\n",
        "    logits = model(input_data)\n",
        "    predicted_class = tf.argmax(logits, axis=-1)\n",
        "\n",
        "    print(f\"예측된 클래스 ID: {predicted_class.numpy()[0]}\")\n",
        "    # 실제 사용 시에는 ImageNet 라벨 맵(Labels map)을 통해 ID를 'Apple', 'Cup' 등의 텍스트로 변환합니다.\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"이미지 로드 실패 또는 오류 발생: {e}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "예측된 클래스 ID: 783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ebbf50c"
      },
      "source": [
        "## 최종 작업\n",
        "\n",
        "### Subtask:\n",
        "오류 해결 및 객체 인식 모델의 성공적인 실행을 확인합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9c1e993"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "The task asked to ensure the `robot_view.jpg` file exists and then successfully execute an object recognition model.\n",
        "The `robot_view.jpg` file did not initially exist, so a dummy image was created. Subsequently, the object recognition model was successfully executed using this dummy image.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   Initially, the `robot_view.jpg` file was confirmed **not to exist** in the current working directory.\n",
        "*   A dummy `robot_view.jpg` image (a 224x224 black image with a green square) was successfully created to fulfill the requirement.\n",
        "*   The object recognition model (MobileNet V2) was successfully executed using the newly created dummy image.\n",
        "*   The model processed the image and predicted a class ID of **783**.\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   To make the object recognition output meaningful, the predicted class ID (783) should be mapped to its corresponding human-readable ImageNet label.\n",
        "*   For real-world application, replace the dummy image generation with actual image capture from the robot's camera to enable practical object recognition.\n"
      ]
    }
  ]
}
